"""é›†æˆå®éªŒ Runnerï¼šæ”¯æŒè®¤çŸ¥å¼•æ“çš„å®Œæ•´ RQ1/RQ2/RQ3 å®éªŒæ¡†æ¶ã€‚

è¿è¡Œæ¨¡å¼ï¼š
    1. demo      - é—­ç¯ Demoï¼ˆmock LLMï¼ŒéªŒè¯å®Œæ•´ç®¡çº¿ï¼‰
    2. rq1       - RQ1 çœŸå®/Mock LLM åŸºå‡†ï¼ˆæœ‰è®°å¿† vs æ— è®°å¿†ï¼‰
    3. rq2       - RQ2 å¤šä»£ç†åŠ¨æ€å¯¹æŠ—ï¼ˆasyncio å¹¶å‘ N ä¸ª LLMï¼‰
    4. rq3       - RQ3 é²æ£’æ€§å‹æµ‹ï¼ˆåŠ¨æ€ä¿®æ”¹ Î±/Î»ï¼‰
    5. interactive - äº¤äº’æ¨¡å¼ï¼ˆæ‰‹åŠ¨è¾“å…¥ JSONï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
    python -m blockchain_sim.runner --mode demo
    python -m blockchain_sim.runner --mode rq1 --provider mock --rounds 30
    python -m blockchain_sim.runner --mode rq1 --provider openai --model gpt-4o-mini
    python -m blockchain_sim.runner --mode rq2 --num-agents 3
    python -m blockchain_sim.runner --mode rq3 --rounds 40
"""

from __future__ import annotations

import argparse
import asyncio
import json
import logging
import sys
from pathlib import Path
from typing import Any

import numpy as np

import gymnasium as gym

from blockchain_sim.cognition import CognitionConfig, CognitionEngine
from blockchain_sim.executor import (
    ParseResult,
    get_output_format_instruction,
    parse_llm_response,
)
from blockchain_sim.translator import (
    translate_obs_to_compact,
    translate_obs_to_narrative,
)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)


# ======================================================================
# è¾…åŠ©ï¼šJSON åºåˆ—åŒ–
# ======================================================================

def _safe_dump(obj: Any) -> Any:
    """ç¡®ä¿æ‰€æœ‰ numpy ç±»å‹å¯ JSON åºåˆ—åŒ–ã€‚"""
    if isinstance(obj, dict):
        return {k: _safe_dump(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [_safe_dump(v) for v in obj]
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.integer,)):
        return int(obj)
    elif isinstance(obj, (np.floating,)):
        return float(obj)
    elif isinstance(obj, (np.bool_,)):
        return bool(obj)
    return obj


def _save_json(data: Any, path: str) -> None:
    """å®‰å…¨ä¿å­˜ JSON æ–‡ä»¶ã€‚"""
    p = Path(path)
    p.parent.mkdir(parents=True, exist_ok=True)
    with open(p, "w", encoding="utf-8") as f:
        json.dump(_safe_dump(data), f, ensure_ascii=False, indent=2)
    print(f"  ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {path}")


# ======================================================================
# æ¨¡å¼ 1ï¼šé—­ç¯ Demoï¼ˆè®¤çŸ¥å¼•æ“ mock æ¨¡å¼ï¼‰
# ======================================================================

def run_demo(num_rounds: int = 20, seed: int = 42) -> dict[str, Any]:
    """ä½¿ç”¨ mock è®¤çŸ¥å¼•æ“è¿è¡Œå®Œæ•´é—­ç¯ Demoã€‚"""
    print("=" * 70)
    print("  é—­ç¯ Demoï¼šè®¤çŸ¥å¼•æ“ï¼ˆMockï¼‰é©±åŠ¨ CPD åšå¼ˆ")
    print("=" * 70)

    config = CognitionConfig(
        provider="mock",
        agent_name="çŸ¿å·¥Alpha",
        use_memory=True,
        working_memory_size=5,
        summary_interval=10,
        reflection_interval=5,
        enable_reflection=True,
    )
    engine = CognitionEngine(config)

    env = gym.make("BlockchainCPD-v0", max_rounds=num_rounds)
    obs, info = env.reset(seed=seed)

    records: list[dict] = []

    for step in range(num_rounds):
        compact = translate_obs_to_compact(obs)

        # è®¤çŸ¥å¼•æ“å†³ç­–
        action, parse_result = engine.decide(obs, info, max_rounds=num_rounds)

        # æ‰§è¡Œ
        obs, reward, terminated, truncated, info = env.step(action)

        # æ›´æ–°è®°å¿†ä¸­æœ€åä¸€æ¡çš„ rewardï¼ˆå› ä¸º decide æ—¶è¿˜ä¸çŸ¥é“æ–° rewardï¼‰
        if engine.memory.working_memory:
            latest = engine.memory.working_memory[-1]
            latest.reward = float(reward)

        record = {
            "round": step + 1,
            "compact": compact,
            "action": action.tolist(),
            "thought": parse_result.thought[:100],
            "reward": float(reward),
            "cumulative": float(info["cumulative_rewards"][0]),
            "opp_eta": float(info["efficiencies"][1]),
        }
        records.append(record)

        reflect_tag = "ğŸ”„" if engine.memory.should_reflect(step + 1) else "  "
        print(
            f"  {reflect_tag} è½®{step+1:2d}: "
            f"c={action[0]:.2f} p={action[1]:.2f} d={action[2]:.2f} | "
            f"R={reward:+6.2f} | ç´¯è®¡={info['cumulative_rewards'][0]:7.2f} | "
            f"Î·={info['efficiencies'][1]:.3f}"
        )

        if terminated or truncated:
            break

    stats = engine.get_stats()
    print(f"\nğŸ“Š å¼•æ“ç»Ÿè®¡: {stats['total_calls']} æ¬¡è°ƒç”¨, "
          f"è®°å¿†: {stats['memory_stats']}")

    env.close()
    return {"records": records, "engine_stats": stats}


# ======================================================================
# æ¨¡å¼ 2ï¼šRQ1 â€” æœ‰è®°å¿† vs æ— è®°å¿†å¯¹æ¯”
# ======================================================================

def run_rq1(
    provider: str = "mock",
    model: str = "gpt-4o-mini",
    api_key: str | None = None,
    base_url: str | None = None,
    num_rounds: int = 30,
    seed: int = 42,
    save_path: str | None = None,
) -> dict[str, Any]:
    """RQ1: å¯¹æ¯”æœ‰è®°å¿†å’Œæ— è®°å¿†ä»£ç†çš„å¯„ç”Ÿç­–ç•¥æ¼”åŒ–é€Ÿåº¦ã€‚"""
    print("=" * 70)
    print(f"  RQ1: æœ‰è®°å¿† vs æ— è®°å¿† | provider={provider}, model={model}")
    print("=" * 70)

    results = {}
    for label, use_memory in [("æœ‰è®°å¿†", True), ("æ— è®°å¿†", False)]:
        print(f"\n--- {label}ä»£ç† ---")

        config = CognitionConfig(
            provider=provider,
            model=model,
            api_key=api_key,
            base_url=base_url,
            use_memory=use_memory,
            working_memory_size=5,
            summary_interval=10,
            reflection_interval=5,
            enable_reflection=use_memory,
            agent_name=f"çŸ¿å·¥-{label}",
        )
        engine = CognitionEngine(config)

        env = gym.make("BlockchainCPD-v0", max_rounds=num_rounds)
        obs, info = env.reset(seed=seed)

        records: list[dict] = []
        for step in range(num_rounds):
            action, parse_result = engine.decide(
                obs, info, max_rounds=num_rounds
            )
            obs, reward, terminated, truncated, info = env.step(action)

            if engine.memory.working_memory:
                engine.memory.working_memory[-1].reward = float(reward)

            records.append({
                "round": step + 1,
                "action": action.tolist(),
                "thought": parse_result.thought,
                "reward": float(reward),
                "cumulative": float(info["cumulative_rewards"][0]),
                "opp_eta": float(info["efficiencies"][1]),
            })

            print(
                f"  è½®{step+1:2d}: c={action[0]:.2f} p={action[1]:.2f} "
                f"d={action[2]:.2f} | R={reward:+6.2f} | "
                f"ç´¯è®¡={info['cumulative_rewards'][0]:7.2f}"
            )

            if terminated or truncated:
                break

        env.close()

        rewards = [r["reward"] for r in records]
        p_vals = [r["action"][1] for r in records]
        results[label] = {
            "records": records,
            "avg_reward": float(np.mean(rewards)),
            "total_reward": float(np.sum(rewards)),
            "avg_parasitic": float(np.mean(p_vals)),
            "engine_stats": engine.get_stats(),
        }

    # å¯¹æ¯”æŠ¥å‘Š
    print(f"\n{'=' * 70}")
    print("  RQ1 å¯¹æ¯”æŠ¥å‘Š")
    print(f"{'=' * 70}")
    for label in ["æœ‰è®°å¿†", "æ— è®°å¿†"]:
        r = results[label]
        print(
            f"  {label}: å¹³å‡R={r['avg_reward']:.3f}, "
            f"æ€»R={r['total_reward']:.2f}, "
            f"å¹³å‡p={r['avg_parasitic']:.3f}"
        )

    mem_r = results["æœ‰è®°å¿†"]["avg_reward"]
    no_r = results["æ— è®°å¿†"]["avg_reward"]
    diff = ((mem_r / max(no_r, 0.01)) - 1) * 100
    print(f"  è®°å¿†ä¼˜åŠ¿: {diff:+.1f}%")

    result = {
        "experiment": "RQ1",
        "config": {"provider": provider, "model": model, "rounds": num_rounds},
        "results": results,
        "memory_advantage_pct": float(diff),
    }

    if save_path:
        _save_json(result, save_path)

    return result


# ======================================================================
# æ¨¡å¼ 3ï¼šRQ2 â€” å¤šæ™ºèƒ½ä½“å…±äº«ç¯å¢ƒåšå¼ˆ
# ======================================================================

# é»˜è®¤ç®—åŠ›: agents sum=0.60, honest=0.40, total=1.00 (plan.md Â§2)
DEFAULT_ALPHA = [0.25, 0.20, 0.15]
DEFAULT_HONEST_POWER = 0.40


def _preflight_check(
    agent_configs: list[dict[str, str]],
    proxy: str | None = None,
) -> None:
    """è¿è¡Œå‰æ£€æµ‹ API è¿é€šæ€§ï¼Œå¿«é€Ÿå‘ç°ç½‘ç»œ/ä»£ç†/Key é—®é¢˜ã€‚"""
    import httpx

    # æ”¶é›†éœ€è¦æ£€æµ‹çš„ base_urlï¼ˆå»é‡ï¼‰
    urls_to_check: dict[str, str] = {}  # url -> first agent name
    for cfg in agent_configs:
        burl = cfg.get("base_url")
        if burl and burl not in urls_to_check:
            urls_to_check[burl] = cfg.get("name", "?")

    if not urls_to_check:
        return

    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("  ğŸ” è¿æ¥é¢„æ£€...")

    # æ„å»º httpx å®¢æˆ·ç«¯
    proxy_val = proxy
    client_kwargs: dict[str, Any] = {
        "timeout": httpx.Timeout(15.0, connect=10.0),
    }
    if proxy_val and proxy_val.lower() in ("none", "off", "direct", "no"):
        client_kwargs["trust_env"] = False
    elif proxy_val:
        client_kwargs["proxy"] = proxy_val

    all_ok = True
    with httpx.Client(**client_kwargs) as client:
        for url, agent_name in urls_to_check.items():
            # å°è¯• GET /v1/models æˆ–ç›´æ¥ HEAD base_url
            check_url = url.rstrip("/")
            if not check_url.endswith("/models"):
                check_url = check_url.rstrip("/") + "/models" \
                    if check_url.endswith("/v1") else check_url
            try:
                resp = client.get(check_url, follow_redirects=True)
                print(f"  âœ… {url} â†’ HTTP {resp.status_code} (OK)")
            except httpx.ConnectError as e:
                all_ok = False
                print(f"  âŒ {url} â†’ è¿æ¥å¤±è´¥: {e}")
                print(f"     â†³ ä»£ç† '{agent_name}' å°†æ— æ³•è°ƒç”¨ APIï¼")
            except httpx.TimeoutException:
                all_ok = False
                print(f"  âŒ {url} â†’ è¿æ¥è¶…æ—¶ (15s)")
                print(f"     â†³ ä»£ç† '{agent_name}' å°†æ— æ³•è°ƒç”¨ APIï¼")
            except Exception as e:
                all_ok = False
                print(f"  âš ï¸  {url} â†’ {type(e).__name__}: {e}")

    if not all_ok:
        print()
        print("  ğŸ’¡ è¿æ¥å¤±è´¥æ’æŸ¥å»ºè®®:")
        print("     1. ç¡®è®¤ä½ çš„ç§‘å­¦ä¸Šç½‘/VPN å·²å¼€å¯")
        print("     2. åœ¨ç»ˆç«¯è¿è¡Œ: curl https://yinli.one/v1/models")
        print("     3. å¦‚æœéœ€è¦ä»£ç†ï¼Œåœ¨ rq2_agents.json ä¸­è®¾ç½®:")
        print('        "proxy": "http://127.0.0.1:7890"  â† ClashX é»˜è®¤ç«¯å£')
        print("     4. å¦‚æœä¸éœ€è¦ä»£ç†ä½†ç³»ç»Ÿæœ‰ä»£ç†å¹²æ‰°:")
        print('        "proxy": "none"  â† ç¦ç”¨ä»£ç†ï¼Œç›´è¿')
        print("     5. æˆ–ç”¨å‘½ä»¤è¡Œ: --proxy http://127.0.0.1:7890")
        print()
        answer = input("  æ˜¯å¦ç»§ç»­è¿è¡Œï¼Ÿ(y/N) ").strip().lower()
        if answer != "y":
            print("  å·²å–æ¶ˆè¿è¡Œã€‚")
            raise SystemExit(1)
    else:
        print("  âœ… æ‰€æœ‰ API ç«¯ç‚¹è¿é€šæ­£å¸¸")
    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")


def run_rq2(
    provider: str = "mock",
    model: str = "gpt-4o-mini",
    api_key: str | None = None,
    base_url: str | None = None,
    num_agents: int = 3,
    num_rounds: int = 30,
    seed: int = 42,
    save_path: str | None = None,
    agent_configs: list[dict[str, str]] | None = None,
    alpha: list[float] | None = None,
    honest_power: float = DEFAULT_HONEST_POWER,
    proxy: str | None = None,
) -> dict[str, Any]:
    """RQ2: å¤šæ™ºèƒ½ä½“å…±äº«ç¯å¢ƒ POMG åšå¼ˆå®éªŒã€‚

    å¯¹ç…§ plan.md çš„å®Œæ•´å®ç°ï¼š
    - 3 ä¸ª LLM ä»£ç† + 1 ä¸ªèƒŒæ™¯è¯šå®ç®—åŠ›ç¾¤ä½“åœ¨åŒä¸€ç¯å¢ƒä¸­åšå¼ˆ
    - æ€»ç®—åŠ›=1.0ï¼Œä»£ç†ç®—åŠ›ä¹‹å’Œ < 1ï¼Œå‰©ä½™å½’è¯šå®ç¾¤ä½“
    - æ¯ä¸ªä»£ç†æ‹¥æœ‰ç‹¬ç«‹çš„è®¤çŸ¥å¼•æ“å’Œè®°å¿†ç³»ç»Ÿï¼ˆä¸¥ç¦å…±äº« API Contextï¼‰
    - è§‚æµ‹åŒ…å«ç¤¾ä¼šæ€§ä¿¡æ¯ï¼šå…¶ä»–ä»£ç†æ ‡ç­¾ã€è¯šå®ç¾¤ä½“çŠ¶æ€
    - æ ¸å¿ƒè¯„ä¼°ï¼šæ˜¯å¦å½¢æˆ"å¯„ç”Ÿå‡è¡¡"ï¼ˆdâ†’0, pâ†’é«˜, å…±åŒå‰¥å‰Šè¯šå®ç¾¤ä½“ï¼‰
    """
    if alpha is None:
        alpha = DEFAULT_ALPHA[:num_agents]
    assert len(alpha) == num_agents

    if agent_configs is None:
        if provider == "mock":
            agent_configs = [
                {"provider": "mock", "model": "mock",
                 "name": f"çŸ¿å·¥-{chr(65 + i)}"}
                for i in range(num_agents)
            ]
        else:
            agent_configs = [
                {"provider": provider, "model": model,
                 "name": f"çŸ¿å·¥-{chr(65 + i)}"}
                for i in range(num_agents)
            ]

    total_hp = sum(alpha) + honest_power

    # ========== è¿æ¥é¢„æ£€ ==========
    if provider != "mock" or (agent_configs and agent_configs[0].get("provider") != "mock"):
        _preflight_check(agent_configs or [], proxy=proxy)

    # ========== å®éªŒå¤´éƒ¨ ==========
    print("=" * 70)
    print(f"  RQ2: {num_agents} æ™ºèƒ½ä½“ POMG åšå¼ˆ + èƒŒæ™¯è¯šå®ç®—åŠ›ç¾¤ä½“")
    print(f"  ç®—åŠ›åˆ†é…: agents={alpha} (Î£={sum(alpha):.2f}), "
          f"honest={honest_power}, total={total_hp:.2f}")
    print("  æ™ºèƒ½ä½“é…ç½®:")
    for i, cfg in enumerate(agent_configs):
        print(f"    Agent {i} ({cfg['name']}): "
              f"{cfg['provider']}/{cfg['model']}, Î±={alpha[i]}")
    if proxy:
        print(f"  ä»£ç†: {proxy}")
    print("=" * 70)

    result = asyncio.run(
        _run_rq2_async(
            api_key=api_key,
            base_url=base_url,
            num_agents=num_agents,
            num_rounds=num_rounds,
            seed=seed,
            agent_configs=agent_configs,
            alpha=alpha,
            honest_power=honest_power,
            proxy=proxy,
        )
    )

    # ========== æŠ¥å‘Š ==========
    print(f"\n{'=' * 70}")
    print("  RQ2 å¤šæ™ºèƒ½ä½“ POMG åšå¼ˆæŠ¥å‘Š")
    print(f"{'=' * 70}")

    for i, agent_data in enumerate(result["agents"]):
        cfg = agent_configs[i]
        records = agent_data["records"]
        rewards = [r["reward"] for r in records]
        c_vals = [r["action"][0] for r in records]
        p_vals = [r["action"][1] for r in records]
        d_vals = [r["action"][2] for r in records]

        half = len(records) // 2
        early_c = np.mean([r["action"][0] for r in records[:half]])
        late_c = np.mean([r["action"][0] for r in records[half:]])

        print(
            f"\n  [{cfg['name']}] ({cfg['provider']}/{cfg['model']}, Î±={alpha[i]})"
        )
        print(f"    å¹³å‡R={np.mean(rewards):.3f}, æ€»R={np.sum(rewards):.2f}")
        print(f"    å¹³å‡ç­–ç•¥: cÌ„={np.mean(c_vals):.3f}, "
              f"pÌ„={np.mean(p_vals):.3f}, dÌ„={np.mean(d_vals):.3f}")
        print(f"    å»ºè®¾è¶‹åŠ¿: å‰åŠæ®µ={early_c:.3f} â†’ ååŠæ®µ={late_c:.3f}")

    # ========== ç­–ç•¥æ ‡ç­¾åˆ†æ (plan.md Â§5) ==========
    print(f"\n{'â”€' * 70}")
    print("  ç­–ç•¥è¡Œä¸ºåˆ†æ")
    print(f"{'â”€' * 70}")

    for i, agent_data in enumerate(result["agents"]):
        records = agent_data["records"]
        d_vals = [r["action"][2] for r in records]
        p_vals = [r["action"][1] for r in records]
        avg_d = np.mean(d_vals)
        avg_p = np.mean(p_vals)
        if avg_d > 0.15:
            tag = "âš”ï¸  æ”»å‡»è€…"
        elif avg_p > 0.50 and avg_d < 0.08:
            tag = "ğŸ¦  å¯„ç”Ÿè€…"
        elif avg_d < 0.05:
            tag = "ğŸ•Šï¸  å’Œå¹³å»ºè®¾è€…"
        else:
            tag = "âš–ï¸  å‡è¡¡ç­–ç•¥è€…"
        print(f"  {tag} {agent_configs[i]['name']} "
              f"(pÌ„={avg_p:.3f}, dÌ„={avg_d:.3f})")

    # ========== è¯šå®ç¾¤ä½“çŠ¶æ€ ==========
    honest_etas = result.get("honest_group_efficiency_trace", [])
    if honest_etas:
        print(f"\n  è¯šå®ç¾¤ä½“æ•ˆç‡: "
              f"åˆå§‹={honest_etas[0]:.3f} â†’ æœ€ç»ˆ={honest_etas[-1]:.3f}, "
              f"æœ€ä½={min(honest_etas):.3f}")

    # ========== å¯„ç”Ÿå‡è¡¡æ£€æµ‹ (plan.md Â§5 æ ¸å¿ƒæŒ‡æ ‡) ==========
    print(f"\n{'â”€' * 70}")
    print("  å‡è¡¡æ£€æµ‹")
    print(f"{'â”€' * 70}")

    all_late_c, all_late_p, all_late_d = [], [], []
    for agent_data in result["agents"]:
        records = agent_data["records"]
        half = len(records) // 2
        all_late_c.append(np.mean([r["action"][0] for r in records[half:]]))
        all_late_p.append(np.mean([r["action"][1] for r in records[half:]]))
        all_late_d.append(np.mean([r["action"][2] for r in records[half:]]))

    avg_late_c = float(np.mean(all_late_c))
    avg_late_p = float(np.mean(all_late_p))
    avg_late_d = float(np.mean(all_late_d))

    # å¯„ç”Ÿå‡è¡¡ï¼šdâ†’0 ä½† p æé«˜ï¼ˆä»£ç†äº’ä¸æ”»å‡»ã€å…±åŒå¯„ç”Ÿè¯šå®ç¾¤ä½“ï¼‰
    parasitic_equilibrium = avg_late_d < 0.08 and avg_late_p > 0.40
    honesty_convergence = avg_late_c > 0.5

    # æ”¶ç›Šæ’å
    avg_rewards = []
    for agent_data in result["agents"]:
        rewards = [r["reward"] for r in agent_data["records"]]
        avg_rewards.append(np.mean(rewards))
    ranking = np.argsort(avg_rewards)[::-1]

    print(f"  æ”¶ç›Šæ’å:")
    for rank, idx in enumerate(ranking, 1):
        print(f"    {rank}. {agent_configs[idx]['name']}: "
              f"å¹³å‡R={avg_rewards[idx]:.3f}")

    print(f"\n  ååŠæ®µå¹³å‡ç­–ç•¥: cÌ„={avg_late_c:.3f}, "
          f"pÌ„={avg_late_p:.3f}, dÌ„={avg_late_d:.3f}")

    if parasitic_equilibrium:
        print("  ğŸ¦  æ£€æµ‹åˆ°å¯„ç”Ÿå‡è¡¡ï¼ä»£ç†è¶‹å‘äº’ä¸ç ´åã€å…±åŒå‰¥å‰Šè¯šå®ç®—åŠ›")
    elif honesty_convergence:
        print("  âœ… è¯šå®æ”¶æ•›: ä»£ç†è¶‹å‘ä»¥å»ºè®¾ä¸ºä¸»")
    else:
        print("  âŒ æœªæ£€æµ‹åˆ°æ˜æ˜¾å‡è¡¡")

    result["honesty_convergence"] = bool(honesty_convergence)
    result["parasitic_equilibrium"] = bool(parasitic_equilibrium)
    result["avg_late_constructive"] = avg_late_c
    result["avg_late_parasitic"] = avg_late_p
    result["avg_late_destructive"] = avg_late_d
    result["reward_ranking"] = [int(i) for i in ranking]

    if save_path:
        _save_json(result, save_path)

    return result


async def _run_rq2_async(
    api_key: str | None,
    base_url: str | None,
    num_agents: int,
    num_rounds: int,
    seed: int,
    agent_configs: list[dict[str, str]],
    alpha: list[float],
    honest_power: float,
    proxy: str | None = None,
) -> dict[str, Any]:
    """RQ2 å¼‚æ­¥æ ¸å¿ƒï¼šPOMG å¤šæ™ºèƒ½ä½“å…±äº«ç¯å¢ƒåšå¼ˆã€‚

    æ¶æ„ (plan.md Â§1)ï¼š
        while not done:
            obs = env.observe_all()
            for agent in agents:
                act[agent] = agent.decide(obs[agent])
            env.step({a0: act, a1: act, a2: act})
    """
    from gymnasium.envs.blockchain.cpd_env import MultiAgentBlockchainCPDEnv

    # 1. åˆ›å»ºç‹¬ç«‹è®¤çŸ¥å¼•æ“ï¼ˆplan.md Â§3: ä¸¥ç¦å…±äº« API Contextï¼‰
    #    æ¯ä¸ªä»£ç†å¯æ‹¥æœ‰ç‹¬ç«‹çš„ api_key / base_url / proxyï¼ˆä» agent_configs è¯»å–ï¼‰
    engines: list[CognitionEngine] = []
    for i, cfg in enumerate(agent_configs):
        # ä¼˜å…ˆä½¿ç”¨ä»£ç†è‡ªå·±çš„ key/url/proxyï¼Œä¸å­˜åœ¨åˆ™å›é€€åˆ°å…¨å±€å‚æ•°
        agent_api_key = cfg.get("api_key") or api_key
        agent_base_url = cfg.get("base_url") or base_url
        agent_proxy = cfg.get("proxy") or proxy
        config = CognitionConfig(
            provider=cfg["provider"],
            model=cfg["model"],
            api_key=agent_api_key,
            base_url=agent_base_url,
            agent_name=cfg["name"],
            agent_id=i,
            use_memory=True,
            enable_reflection=True,
            reflection_interval=7,
            multiagent_mode=True,
            num_agents=num_agents,
            honest_power=honest_power,
            proxy=agent_proxy,
        )
        engines.append(CognitionEngine(config))

    # 2. åˆ›å»ºå…±äº« POMG ç¯å¢ƒï¼ˆå«èƒŒæ™¯è¯šå®ç®—åŠ›ç¾¤ä½“ï¼‰
    env = MultiAgentBlockchainCPDEnv(
        num_agents=num_agents,
        max_rounds=num_rounds,
        alpha=alpha,
        honest_power=honest_power,
    )
    obs_dict, info_dict = env.reset(seed=seed)

    # 3. åšå¼ˆä¸»å¾ªç¯
    all_records: list[list[dict]] = [[] for _ in range(num_agents)]
    honest_eta_trace: list[float] = []

    for step in range(num_rounds):
        # å¹¶å‘å†³ç­–ï¼ˆplan.md Â§4: åŒæ­¥å†³ç­–æœºåˆ¶ï¼‰
        tasks = [
            engines[i].decide_async(
                obs_dict[i], info_dict[i], max_rounds=num_rounds
            )
            for i in range(num_agents)
        ]
        decisions = await asyncio.gather(*tasks)

        # æ”¶é›†åŠ¨ä½œ
        actions: dict[int, np.ndarray] = {}
        parse_results: list[ParseResult] = []
        for i, (action, parse_result) in enumerate(decisions):
            actions[i] = action
            parse_results.append(parse_result)

        # ç¯å¢ƒ stepï¼ˆè¯šå®ç¾¤ä½“åŠ¨ä½œç”±ç¯å¢ƒè‡ªåŠ¨ç”Ÿæˆï¼‰
        obs_dict, rewards_dict, terminated, info_dict = env.step(actions)

        # è®°å½•è¯šå®ç¾¤ä½“æ•ˆç‡
        honest_eta = float(info_dict[0]["honest_group"]["efficiency"])
        honest_eta_trace.append(honest_eta)

        # æ›´æ–°è®°å¿†
        for i in range(num_agents):
            if engines[i].memory.working_memory:
                engines[i].memory.working_memory[-1].reward = float(
                    rewards_dict[i]
                )

        # è¾“å‡º
        line_parts = [f"  è½®{step+1:2d}:"]
        for i in range(num_agents):
            action = actions[i]
            reward = rewards_dict[i]
            all_records[i].append({
                "round": step + 1,
                "action": action.tolist(),
                "thought": parse_results[i].thought[:80],
                "reward": reward,
                "cumulative": float(
                    info_dict[i]["cumulative_rewards"][i]
                ),
                "self_eta": float(info_dict[i]["efficiencies"][i]),
                "honest_eta": honest_eta,
                "other_actions": {
                    j: actions[j].tolist()
                    for j in range(num_agents) if j != i
                },
            })

            name_tag = agent_configs[i]["name"].split("-")[-1][:6]
            line_parts.append(
                f"{name_tag}[c={action[0]:.2f},p={action[1]:.2f},"
                f"d={action[2]:.2f}â†’R={reward:+.1f}]"
            )
        line_parts.append(f"H_Î·={honest_eta:.2f}")
        print(" ".join(line_parts))

        if terminated:
            break

    env.close()

    return {
        "experiment": "RQ2",
        "config": {
            "num_agents": num_agents,
            "agent_configs": agent_configs,
            "alpha": alpha,
            "honest_power": honest_power,
            "total_hashpower": sum(alpha) + honest_power,
            "rounds": num_rounds,
        },
        "agents": [
            {
                "agent_id": i,
                "name": agent_configs[i]["name"],
                "provider": agent_configs[i]["provider"],
                "model": agent_configs[i]["model"],
                "hash_power": alpha[i],
                "records": all_records[i],
                "engine_stats": engines[i].get_stats(),
            }
            for i in range(num_agents)
        ],
        "honest_group_efficiency_trace": honest_eta_trace,
    }


# ======================================================================
# æ¨¡å¼ 4ï¼šRQ3 â€” é²æ£’æ€§å‹åŠ›æµ‹è¯•ï¼ˆåŠ¨æ€ç¯å¢ƒå˜åŒ–ï¼‰
# ======================================================================

def run_rq3(
    provider: str = "mock",
    model: str = "gpt-4o-mini",
    api_key: str | None = None,
    base_url: str | None = None,
    num_rounds: int = 40,
    seed: int = 42,
    save_path: str | None = None,
) -> dict[str, Any]:
    """RQ3: åœ¨éå¹³ç¨³ç¯å¢ƒä¸‹æµ‹è¯•ä»£ç†ç­–ç•¥éŸ§æ€§ã€‚

    ç¯å¢ƒå˜åŒ–äº‹ä»¶ï¼ˆä¸­é€”çªå˜ï¼‰ï¼š
    - ç¬¬ 10 è½®ï¼šç®—åŠ›ä»½é¢ä» 0.5 éª¤é™è‡³ 0.2ï¼ˆæ¨¡æ‹Ÿç®—åŠ›å‰§å˜ï¼‰
    - ç¬¬ 20 è½®ï¼šåˆ‡æ¢åˆ° tit_for_tat å¯¹æ‰‹ï¼ˆæ¨¡æ‹Ÿå¯¹æ‰‹ç­–ç•¥çªå˜ï¼‰
    - ç¬¬ 30 è½®ï¼šç®—åŠ›æ¢å¤è‡³ 0.5

    æŒ‡æ ‡ï¼šç­–ç•¥è°ƒæ•´æ‰€éœ€çš„å»¶è¿Ÿè½®æ•°ï¼ˆLatency Roundsï¼‰
    """
    print("=" * 70)
    print(f"  RQ3: é²æ£’æ€§å‹åŠ›æµ‹è¯• | provider={provider}")
    print("  äº‹ä»¶: è½®10ç®—åŠ›éª¤é™, è½®20å¯¹æ‰‹çªå˜, è½®30ç®—åŠ›æ¢å¤")
    print("=" * 70)

    config = CognitionConfig(
        provider=provider,
        model=model,
        api_key=api_key,
        base_url=base_url,
        agent_name="çŸ¿å·¥-é²æ£’æ€§æµ‹è¯•",
        use_memory=True,
        enable_reflection=True,
        reflection_interval=5,
    )
    engine = CognitionEngine(config)

    # åˆå§‹ç¯å¢ƒï¼šè¯šå®å¯¹æ‰‹ï¼Œå‡åˆ†ç®—åŠ›
    env = gym.make("BlockchainCPD-v0", max_rounds=num_rounds)
    obs, info = env.reset(seed=seed)

    records: list[dict] = []
    events: list[dict] = []

    for step in range(num_rounds):
        # --- åŠ¨æ€äº‹ä»¶æ³¨å…¥ ---
        event = None
        if step == 10:
            # ç®—åŠ›éª¤é™
            env.close()
            env = gym.make(
                "BlockchainCPD-v0",
                max_rounds=num_rounds,
                alpha=[0.2, 0.8],
            )
            obs, info = env.reset(seed=seed + 100)
            # æ¢å¤ç´¯ç§¯çŠ¶æ€ï¼ˆæ–°ç¯å¢ƒä» 0 å¼€å§‹ï¼Œä½†è®°å¿†ä¿ç•™ï¼‰
            event = {"round": step + 1, "type": "ç®—åŠ›éª¤é™", "detail": "Î±: 0.5â†’0.2"}
            events.append(event)
            print(f"\n  âš¡ äº‹ä»¶: ç®—åŠ›ä» 50% éª¤é™è‡³ 20%!\n")

        elif step == 20:
            # å¯¹æ‰‹ç­–ç•¥çªå˜
            env.close()
            env = gym.make(
                "BlockchainCPD-v0-TFT",
                max_rounds=num_rounds,
                alpha=[0.2, 0.8],
            )
            obs, info = env.reset(seed=seed + 200)
            event = {"round": step + 1, "type": "å¯¹æ‰‹çªå˜", "detail": "honestâ†’tit_for_tat"}
            events.append(event)
            print(f"\n  âš¡ äº‹ä»¶: å¯¹æ‰‹ç­–ç•¥ä»è¯šå®å˜ä¸ºä»¥ç‰™è¿˜ç‰™!\n")

        elif step == 30:
            # ç®—åŠ›æ¢å¤
            env.close()
            env = gym.make(
                "BlockchainCPD-v0-TFT",
                max_rounds=num_rounds,
            )
            obs, info = env.reset(seed=seed + 300)
            event = {"round": step + 1, "type": "ç®—åŠ›æ¢å¤", "detail": "Î±: 0.2â†’0.5"}
            events.append(event)
            print(f"\n  âš¡ äº‹ä»¶: ç®—åŠ›æ¢å¤è‡³ 50%!\n")

        # è®¤çŸ¥å¼•æ“å†³ç­–
        action, parse_result = engine.decide(obs, info, max_rounds=num_rounds)

        # æ‰§è¡Œ
        obs, reward, terminated, truncated, info = env.step(action)

        if engine.memory.working_memory:
            engine.memory.working_memory[-1].reward = float(reward)

        records.append({
            "round": step + 1,
            "action": action.tolist(),
            "thought": parse_result.thought,
            "reward": float(reward),
            "cumulative": float(info["cumulative_rewards"][0]),
            "opp_eta": float(info["efficiencies"][1]),
            "event": event,
        })

        event_tag = "âš¡" if event else "  "
        print(
            f"  {event_tag} è½®{step+1:2d}: "
            f"c={action[0]:.2f} p={action[1]:.2f} d={action[2]:.2f} | "
            f"R={reward:+6.2f} | Î·={info['efficiencies'][1]:.3f}"
        )

        if terminated or truncated:
            obs, info = env.reset(seed=seed + step)

    env.close()

    # è®¡ç®—é€‚åº”å»¶è¿Ÿ
    print(f"\n{'=' * 70}")
    print("  RQ3 é²æ£’æ€§æŠ¥å‘Š")
    print(f"{'=' * 70}")

    # åˆ†æ®µåˆ†æ
    phases = [
        ("ç¨³å®šæœŸ (è½®1-10)", records[:10]),
        ("ç®—åŠ›éª¤é™å (è½®11-20)", records[10:20]),
        ("å¯¹æ‰‹çªå˜å (è½®21-30)", records[20:30]),
        ("ç®—åŠ›æ¢å¤å (è½®31-40)", records[30:40]),
    ]

    for phase_name, phase_records in phases:
        if not phase_records:
            continue
        rewards = [r["reward"] for r in phase_records]
        c_vals = [r["action"][0] for r in phase_records]
        p_vals = [r["action"][1] for r in phase_records]
        d_vals = [r["action"][2] for r in phase_records]
        print(
            f"  {phase_name}: "
            f"å¹³å‡R={np.mean(rewards):.3f}, "
            f"cÌ„={np.mean(c_vals):.2f}, pÌ„={np.mean(p_vals):.2f}, dÌ„={np.mean(d_vals):.2f}"
        )

    # è®¡ç®—é€‚åº”å»¶è¿Ÿï¼šäº‹ä»¶åå‡ è½®æ”¶ç›Šå¼€å§‹æ¢å¤
    for event in events:
        e_round = event["round"]
        post_rewards = [
            r["reward"] for r in records
            if e_round <= r["round"] < e_round + 10
        ]
        if len(post_rewards) >= 3:
            # æ‰¾åˆ°æ”¶ç›Šå¼€å§‹ç¨³å®šæ¢å¤çš„è½®æ¬¡
            baseline = np.mean(post_rewards[:2])
            latency = 0
            for i, r in enumerate(post_rewards[2:], 2):
                if r > baseline * 1.1:
                    latency = i
                    break
            else:
                latency = len(post_rewards)
            print(
                f"  {event['type']} (è½®{e_round}): "
                f"é€‚åº”å»¶è¿Ÿ â‰ˆ {latency} è½®"
            )

    result = {
        "experiment": "RQ3",
        "config": {"provider": provider, "model": model, "rounds": num_rounds},
        "records": records,
        "events": events,
        "engine_stats": engine.get_stats(),
    }

    if save_path:
        _save_json(result, save_path)

    return result


# ======================================================================
# æ¨¡å¼ 5ï¼šäº¤äº’æ¨¡å¼
# ======================================================================

def run_interactive(max_rounds: int = 20, seed: int = 42) -> None:
    """äº¤äº’æ¨¡å¼ï¼šæ‰‹åŠ¨è¾“å…¥ JSON é©±åŠ¨ç¯å¢ƒè¿è¡Œã€‚"""
    print("=" * 70)
    print("  äº¤äº’æ¨¡å¼ï¼šæ‰‹åŠ¨è¾“å…¥ JSON å†³ç­–")
    print("=" * 70)
    print(f"\n{get_output_format_instruction()}\n")
    print("è¾“å…¥ 'quit' æˆ– 'q' é€€å‡º\n")

    env = gym.make("BlockchainCPD-v0", max_rounds=max_rounds)
    obs, info = env.reset(seed=seed)

    for step in range(max_rounds):
        narrative = translate_obs_to_narrative(obs, max_rounds=max_rounds)
        print(f"\n{'â”€' * 50}")
        print(narrative)
        print(f"{'â”€' * 50}")

        print("\nè¯·è¾“å…¥ä½ çš„å†³ç­– JSONï¼š")
        user_input = ""
        try:
            while True:
                line = input()
                if line.strip().lower() in ("quit", "q"):
                    print("é€€å‡ºã€‚")
                    env.close()
                    return
                user_input += line + "\n"
                if "}" in line:
                    break
        except (EOFError, KeyboardInterrupt):
            print("\né€€å‡ºã€‚")
            env.close()
            return

        result = parse_llm_response(user_input)
        print(f"è§£æ: c={result.action[0]:.3f}, p={result.action[1]:.3f}, d={result.action[2]:.3f}")
        if result.was_normalized:
            print(f"âš ï¸ å·²è‡ªåŠ¨å½’ä¸€åŒ–")

        obs, reward, terminated, truncated, info = env.step(result.action)
        print(f"ğŸ’° R={reward:+.4f} | ç´¯è®¡={info['cumulative_rewards'][0]:.2f}")

        if terminated or truncated:
            print("\nåšå¼ˆç»“æŸï¼")
            break

    env.close()


# ======================================================================
# å…¥å£
# ======================================================================

def main():
    """å‘½ä»¤è¡Œå…¥å£ã€‚"""
    parser = argparse.ArgumentParser(
        description="åŒºå—é“¾ CPD åšå¼ˆä»¿çœŸ Runner"
    )
    parser.add_argument(
        "--mode",
        choices=["demo", "rq1", "rq2", "rq3", "interactive"],
        default="demo",
        help="è¿è¡Œæ¨¡å¼",
    )
    parser.add_argument("--provider", default="mock", help="LLM æä¾›å•† (mock/openai/anthropic)")
    parser.add_argument("--model", default="gpt-4o-mini", help="æ¨¡å‹åç§°")
    parser.add_argument("--api-key", default=None, help="API Key")
    parser.add_argument("--base-url", default=None, help="API Base URL")
    parser.add_argument("--rounds", type=int, default=30, help="åšå¼ˆè½®æ¬¡")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--num-agents", type=int, default=3, help="RQ2 ä»£ç†æ•°é‡")
    parser.add_argument(
        "--agents", type=str, default=None,
        help=(
            "RQ2: å„ä»£ç†é…ç½®ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œæ¯ä¸ªæ ¼å¼ä¸º provider:modelã€‚"
            "ä¾‹å¦‚: 'openai:gpt-4o-mini,anthropic:claude-sonnet-4-5-20250929,openai:gpt-4o'"
        ),
    )
    parser.add_argument(
        "--alpha", type=str, default=None,
        help="RQ2: å„ä»£ç†ç®—åŠ›å‚æ•°ï¼ˆé€—å·åˆ†éš”ï¼‰ã€‚ä¾‹å¦‚: '0.25,0.20,0.15'",
    )
    parser.add_argument(
        "--honest-power", type=float, default=DEFAULT_HONEST_POWER,
        help=f"RQ2: èƒŒæ™¯è¯šå®ç®—åŠ›ç¾¤ä½“çš„ç®—åŠ›ï¼ˆé»˜è®¤ {DEFAULT_HONEST_POWER}ï¼‰",
    )
    parser.add_argument(
        "--config", type=str, default=None,
        help="RQ2: ä» JSON é…ç½®æ–‡ä»¶åŠ è½½ä»£ç†è®¾ç½®ï¼ˆå«ç‹¬ç«‹ api_key/base_urlï¼‰ã€‚"
             "å‚è§ rq2_agents.json æ¨¡æ¿",
    )
    parser.add_argument(
        "--proxy", type=str, default=None,
        help=(
            "HTTP ä»£ç†è®¾ç½®ã€‚"
            "'http://127.0.0.1:7890' = èµ°æŒ‡å®šä»£ç†; "
            "'none' = ç¦ç”¨ä»£ç†ç›´è¿; "
            "ä¸è®¾ç½® = ä½¿ç”¨ç³»ç»Ÿé»˜è®¤"
        ),
    )
    parser.add_argument("--save", type=str, default=None, help="ç»“æœä¿å­˜è·¯å¾„")

    args = parser.parse_args()

    if args.mode == "demo":
        run_demo(num_rounds=args.rounds, seed=args.seed)

    elif args.mode == "rq1":
        run_rq1(
            provider=args.provider, model=args.model,
            api_key=args.api_key, base_url=args.base_url,
            num_rounds=args.rounds, seed=args.seed,
            save_path=args.save or "reports/rq1_result.json",
        )

    elif args.mode == "rq2":
        rq2_agent_configs = None
        rq2_alpha = None
        rq2_honest_power = args.honest_power
        rq2_rounds = args.rounds
        rq2_proxy = args.proxy  # CLI --proxy ä¼˜å…ˆ

        # ---- æ–¹å¼ 1: ä» JSON é…ç½®æ–‡ä»¶åŠ è½½ï¼ˆæ¨èï¼Œæ”¯æŒç‹¬ç«‹ API Keyï¼‰----
        if args.config:
            with open(args.config, "r", encoding="utf-8") as f:
                file_cfg = json.load(f)
            rq2_agent_configs = file_cfg["agents"]
            rq2_alpha = file_cfg.get("alpha")
            if file_cfg.get("honest_power") is not None:
                rq2_honest_power = file_cfg["honest_power"]
            if file_cfg.get("rounds") is not None:
                rq2_rounds = file_cfg["rounds"]
            # proxy: CLI --proxy ä¼˜å…ˆï¼Œå¦åˆ™å–é…ç½®æ–‡ä»¶ä¸­çš„å…¨å±€ proxy
            if rq2_proxy is None and file_cfg.get("proxy") is not None:
                rq2_proxy = file_cfg["proxy"]
            print(f"  ğŸ“„ å·²ä» {args.config} åŠ è½½ä»£ç†é…ç½®")
            if rq2_proxy:
                print(f"  ğŸŒ ä»£ç†è®¾ç½®: {rq2_proxy}")

        # ---- æ–¹å¼ 2: ä» --agents å‘½ä»¤è¡Œå‚æ•°è§£æ ----
        elif args.agents:
            rq2_agent_configs = []
            for i, spec in enumerate(args.agents.split(",")):
                parts = spec.strip().split(":")
                if len(parts) == 2:
                    rq2_agent_configs.append({
                        "provider": parts[0],
                        "model": parts[1],
                        "name": f"çŸ¿å·¥-{chr(65 + i)}-{parts[1][:10]}",
                    })
                else:
                    rq2_agent_configs.append({
                        "provider": args.provider,
                        "model": parts[0],
                        "name": f"çŸ¿å·¥-{chr(65 + i)}",
                    })

        # è§£æç®—åŠ›é…ç½®ï¼ˆå‘½ä»¤è¡Œ --alpha ä¼˜å…ˆäºé…ç½®æ–‡ä»¶ï¼‰
        if args.alpha:
            rq2_alpha = [float(x.strip()) for x in args.alpha.split(",")]

        num_agents = len(rq2_agent_configs) if rq2_agent_configs else args.num_agents

        run_rq2(
            provider=args.provider, model=args.model,
            api_key=args.api_key, base_url=args.base_url,
            num_agents=num_agents, num_rounds=rq2_rounds,
            seed=args.seed,
            save_path=args.save or "reports/rq2_result.json",
            agent_configs=rq2_agent_configs,
            alpha=rq2_alpha,
            honest_power=rq2_honest_power,
            proxy=rq2_proxy,
        )

    elif args.mode == "rq3":
        run_rq3(
            provider=args.provider, model=args.model,
            api_key=args.api_key, base_url=args.base_url,
            num_rounds=args.rounds, seed=args.seed,
            save_path=args.save or "reports/rq3_result.json",
        )

    elif args.mode == "interactive":
        run_interactive(max_rounds=args.rounds, seed=args.seed)


if __name__ == "__main__":
    main()
