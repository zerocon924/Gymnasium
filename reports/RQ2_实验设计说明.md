# 实验二（RQ2）设计说明：多智能体 LLM 区块链博弈

## 一、研究问题

**RQ2：当多个具有独立记忆和推理能力的 LLM 智能体在同一区块链环境中竞争时，它们是否会涌现出"寄生均衡"——即互不破坏、共同剥削诚实算力群体的策略协调？**

---

## 二、建模框架：部分观测马尔可夫博弈（POMG）

### 2.1 为什么选择 POMG

传统的单智能体实验（RQ1）将区块链建模为马尔可夫决策过程（MDP），环境是静态的、无记忆的。但在真实公链场景中，矿工面对的是**其他有策略意识的参与者**，而非固定策略的NPC。因此 RQ2 将建模范式从 MDP 升级为**部分观测马尔可夫博弈（Partially Observed Markov Game, POMG）**：

- **部分观测**：每个智能体只能看到其他智能体的公开状态（效率、累计收益、策略倾向标签），看不到对方的内部记忆和推理过程。
- **马尔可夫博弈**：所有智能体共享同一个环境状态，每一步的状态转移和收益都取决于**所有参与者的联合动作**。
- **动态耦合**：一个智能体的破坏行为会实时降低其他所有参与者的效率，形成链式反应。

### 2.2 参与者构成

| 角色 | 数量 | 算力（α） | 决策方式 |
|------|------|-----------|---------|
| LLM 智能体 A | 1 | 0.25 | GPT-4o-mini 驱动 |
| LLM 智能体 B | 1 | 0.20 | Claude Sonnet 4.5 驱动 |
| LLM 智能体 C | 1 | 0.15 | GPT-4o 驱动 |
| 背景诚实算力群体 | 1 | 0.40 | 固定纯建设策略 [1,0,0] |
| **合计** | **4** | **1.00** | — |

**设计意图**：
- 三个 LLM 智能体使用**不同的大语言模型**，以观察不同模型的策略差异和认知特征。
- **背景诚实算力群体**（Honest Group）占总算力的 40%，始终执行纯建设策略 `[c=1, p=0, d=0]`。它代表区块链协议中遵循规则的"沉默多数"，是被寄生剥削的潜在目标，也是检验"寄生均衡"假说的关键要素。
- 总算力严格归一化至 1.0，符合 SquirRL 论文第六章的算力建模设定。

---

## 三、行动空间：CPD 资源分配

每个 LLM 智能体在每一轮中输出一个三维**CPD 向量** `[c, p, d]`，满足 `c + p + d = 1`：

| 维度 | 含义 | 经济学解释 |
|------|------|-----------|
| **c**（Constructive，建设） | 投入合法挖矿的资源比例 | 产出与自身算力成正比，是最稳健的收益来源 |
| **p**（Parasitic，寄生） | 投入搭便车/自私挖矿的资源比例 | 收益依赖于对手的效率（η），对手效率越高、寄生收益越大 |
| **d**（Destructive，破坏） | 投入攻击/破坏对手的资源比例 | 降低所有其他参与者的效率，但自身承担二次惩罚成本 |

**Simplex 归一化**：无论 LLM 输出什么数值，系统都会自动归一化至 `c + p + d = 1`，确保动作合法。

---

## 四、收益机制（Reward）

每一轮中，智能体 $i$ 的收益 $U_i$ 由三个部分组成：

$$
U_i = \underbrace{R \cdot \alpha_i \cdot c_i}_{\text{建设收益}} + \underbrace{R \cdot p_i \cdot (\bar{\eta}_{-i})^{\beta}}_{\text{寄生收益}} - \underbrace{\lambda \cdot d_i^2}_{\text{破坏成本}}
$$

其中：
- $R = 10$：每轮区块总奖励
- $\alpha_i$：智能体 $i$ 的算力份额
- $\bar{\eta}_{-i}$：**所有对手**（包括其他 LLM 智能体和诚实群体）的平均效率
- $\beta = 1.5$：寄生收益的凸性系数（对手效率越低，寄生收益衰减越快）
- $\lambda = 2.0$：破坏行为的二次惩罚系数

**核心耦合机制**：寄生收益 $(\bar{\eta}_{-i})^{1.5}$ 直接依赖对手效率。这意味着：
- 如果大量破坏导致所有人效率崩溃，寄生行为也会变得无利可图
- 存在一个"最优剥削点"：让对手效率保持适度水平，才能最大化寄生收益
- 这正是"寄生均衡"假说的经济学基础

---

## 五、效率动态（Efficiency η）

每个参与者维护一个效率值 $\eta_i \in [0.1, 1.0]$，初始为 1.0：

$$
\eta_i^{t+1} = \text{clamp}\left(\eta_i^t - \kappa \cdot \sum_{j \neq i} d_j + \gamma, \ 0.1, \ 1.0\right)
$$

- $\kappa = 0.2$：破坏传导系数——对手每投入 1 单位破坏资源，目标效率下降 0.2
- $\gamma = 0.05$：自然恢复率——每轮自动恢复 0.05
- 下限 $\eta_{min} = 0.1$：效率不会完全归零

**诚实群体同样受到破坏影响**：这是关键设计。当三个 LLM 智能体都进行破坏时，诚实群体的效率也会下降，导致全网效率螺旋式崩溃。

---

## 六、认知架构：独立认知引擎

每个 LLM 智能体配备**完全隔离的认知引擎（CognitionEngine）**，严禁共享 API 上下文：

### 6.1 决策流程

```
每一轮:
  1. 环境 → 生成各智能体的观测（obs）和信息（info）
  2. 翻译层（Translator）→ 将数值观测转为自然语言叙事
     - 全网态势描述
     - 诚实群体状态
     - 各竞争对手的策略标签和效率变化
  3. 记忆模块（Memory）→ 注入历史上下文
     - 长期记忆：情节性总结（每10轮压缩一次）
     - 短期记忆：最近5轮的完整交互记录
     - 最新反思结论
  4. LLM 推理 → 生成思维链（CoT）+ 动作
     - 态势感知 → 对手建模 → 诚实群体分析 → 成本收益 → 社会推理 → 决策
  5. 执行层（Executor）→ 解析 LLM 输出为 [c, p, d] 向量
  6. 环境 → 接收所有智能体的动作，计算收益和新状态
  7. 记忆更新 → 将本轮结果写入工作记忆
  8. 反思触发 → 每7轮执行一次策略反思
```

### 6.2 提示词设计

**系统提示词**包含：
- 智能体身份（代号、算力份额）
- CPD 博弈规则和收益公式
- 多方博弈环境描述（3 个 LLM 智能体 + 1 个诚实群体）
- **社会推理指令**：要求 LLM 给对手贴标签（攻击者？寄生者？建设者？）
- **寄生均衡警示**：提示可能存在"互不破坏、共同剥削诚实群体"的均衡

**用户提示词**包含：
- 完整的记忆上下文（长期 + 短期）
- 当前轮的环境叙事（包含社会性描述）
- 输出格式要求（JSON：thought + action）

### 6.3 思维链约束（CoT）

每个智能体的推理过程被要求包含以下步骤：

1. **态势感知**：当前全网状态、诚实群体效率
2. **对手建模**：给每个对手贴标签（攻击者/寄生者/建设者）
3. **诚实群体分析**：诚实群体的效率趋势，是否适合寄生
4. **成本收益分析**：破坏的二次成本 vs 建设和寄生的边际收益
5. **社会推理**：预判对手对我方行为的可能反应
6. **最终决策**：输出 `[c, p, d]` 并给出理由

---

## 七、记忆系统：双层记忆 + 反思机制

### 7.1 工作记忆（短期，最近 5 轮）

存储每轮的完整信息：决策、推理、收益、对手效率。为 LLM 提供即时上下文，捕捉对手策略的短期变化。

### 7.2 情节性总结（长期，每 10 轮压缩）

将过去若干轮的数据统计压缩为紧凑的叙事摘要，包含平均收益、策略趋势、最佳/最差轮次、关键发现。节省 token 同时保留长期策略记忆。

### 7.3 反思机制（每 7 轮触发）

暂停常规决策，让 LLM 回顾自己的历史表现并规划策略调整。反思结果存入私有日志，作为后续决策的参考。

**三个记忆组件完全独立**：Agent A 的记忆对 Agent B 和 C 完全不可见，确保认知隔离。

---

## 八、观测设计：社会性信息

每个智能体的观测包含两部分：

### 8.1 数值观测（6 维向量）
```
[累计收益, 对手平均效率, 自身算力份额, 博弈进度, 上轮收益, 效率变化量]
```

### 8.2 社会性信息（info 字典）

| 信息项 | 内容 |
|--------|------|
| `other_agents` | 每个竞争对手的：上轮动作、效率、累计收益、算力、**策略标签** |
| `honest_group` | 诚实群体的：算力、效率、累计收益 |
| `strategy_label` | 系统自动推导的策略标签（诚实建设者/攻击者/寄生搭便车者/机会主义者/均衡策略者） |

**策略标签推导规则**：
- `c ≥ 0.6` → "诚实建设者"
- `d ≥ 0.25` → "攻击者"
- `p ≥ 0.5` → "寄生搭便车者"
- `p ≥ 0.3 且 d ≥ 0.15` → "机会主义者"
- 其他 → "均衡策略者"

翻译层将以上数值信息转换为自然语言叙事，例如：
> "当前全网有 3 个智能矿工 + 背景诚实算力群体。诚实群体效率为 0.85（高效运转中）。矿工-B（策略标签：攻击者）效率 0.72，正在发动攻击，可能对你造成效率损失。"

---

## 九、同步决策与并发执行

所有 LLM 智能体在每一轮中**同步决策**：

1. 环境生成上一轮的"全网状态"
2. 三个智能体**并发调用 LLM API**（`asyncio.gather`），各自独立推理
3. 所有动作提交后，环境统一计算收益和状态转移
4. 诚实群体的固定动作 `[1,0,0]` 在环境内部自动注入

这保证了博弈的**同时移动**特性——没有人能看到本轮对手的动作后再做决定。

---

## 十、核心评估指标

### 10.1 寄生均衡检测

定义：在博弈后半段（后 15 轮），如果满足以下条件，则判定为"寄生均衡"：
- 平均破坏比例 $\bar{d} < 0.08$（几乎不破坏）
- 平均寄生比例 $\bar{p} > 0.40$（高度寄生）

**寄生均衡意味着**：三个 LLM 智能体"心照不宣"地停止了互相攻击，转而共同通过寄生行为剥削诚实算力群体的贡献。

### 10.2 诚实收敛检测

定义：在博弈后半段，如果 $\bar{c} > 0.55$（建设为主），则判定为"诚实收敛"。

### 10.3 其他指标

| 指标 | 说明 |
|------|------|
| 策略行为标签 | 根据平均 CPD 分配将每个智能体归类 |
| 诚实群体效率轨迹 | 追踪诚实群体的效率随时间的变化 |
| 收益排名 | 比较不同 LLM 模型的博弈表现 |
| 建设趋势 | 比较前半段 vs 后半段的建设比例变化 |

---

## 十一、实验结果速览

在默认配置（30 轮，α=[0.25, 0.20, 0.15]，honest=0.40）下的运行结果：

| 结论指标 | 结果 |
|---------|------|
| 寄生均衡？ | **否**（后半段 $\bar{d}=0.156 > 0.08$） |
| 诚实收敛？ | **是**（后半段 $\bar{c}=0.616 > 0.55$） |
| 诚实群体效率 | 0.96 → 0.10（第 9 轮后触底，持续处于下限） |
| 收益排名 | Agent A (GPT-4o-mini) > Agent C (GPT-4o) > Agent B (Claude) |

**核心发现**：
- 三个智能体**没有形成寄生均衡**，而是趋向"以建设为主"的策略
- 但诚实群体的效率被快速摧毁至下限 0.1，说明早期存在大量破坏行为
- 随着诚实群体效率崩溃，寄生行为的回报接近零，智能体被迫回归建设
- 这揭示了一个有趣的**动态过程**：早期攻击 → 效率崩溃 → 寄生失效 → 被迫诚实

---

## 十二、技术实现要点

| 模块 | 文件 | 核心职责 |
|------|------|---------|
| 环境 | `gymnasium/envs/blockchain/cpd_env.py` | `MultiAgentBlockchainCPDEnv`：POMG 环境，管理所有参与者 |
| 认知 | `blockchain_sim/cognition.py` | `CognitionEngine`：LLM 调用、提示词构建、记忆整合 |
| 翻译 | `blockchain_sim/translator.py` | 数值观测 → 自然语言叙事（含社会性描述） |
| 记忆 | `blockchain_sim/memory.py` | `DualLayerMemory`：双层记忆 + 反思 |
| 执行 | `blockchain_sim/executor.py` | LLM 文本输出 → `[c, p, d]` 动作向量 |
| 编排 | `blockchain_sim/runner.py` | `run_rq2()`：实验编排、并发控制、报告生成 |
| 配置 | `rq2_agents.json` | 智能体模型、API Key、算力、代理设置 |
